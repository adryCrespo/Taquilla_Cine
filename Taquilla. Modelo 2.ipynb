{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96af0d64",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Diferencias-con-respecto-al-modelo-1\" data-toc-modified-id=\"Diferencias-con-respecto-al-modelo-1-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Diferencias con respecto al modelo 1</a></span></li><li><span><a href=\"#FUNCIONES\" data-toc-modified-id=\"FUNCIONES-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>FUNCIONES</a></span></li><li><span><a href=\"#TRAIN\" data-toc-modified-id=\"TRAIN-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>TRAIN</a></span></li><li><span><a href=\"#TEST\" data-toc-modified-id=\"TEST-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>TEST</a></span></li><li><span><a href=\"#Usando-pipelines\" data-toc-modified-id=\"Usando-pipelines-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Usando pipelines</a></span><ul class=\"toc-item\"><li><span><a href=\"#TEST-PIPELINE\" data-toc-modified-id=\"TEST-PIPELINE-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>TEST PIPELINE</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49cf4834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acrespod\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "C:\\Users\\acrespod\\Anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "#Automcompletar rápido\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ca5d14",
   "metadata": {},
   "source": [
    "# Diferencias con respecto al modelo 1\n",
    "He usado informacion sobre:  \n",
    "   - genero de la pelicula  \n",
    "   -  los paises de produccion  \n",
    "   - las compañias de produccion    \n",
    "   - keywords de la peli  \n",
    "   - nombres del cast  \n",
    "   - nombres comunes de crew    \n",
    "Todas estas variables han sido codificadas con la tecnica one hot encoding.    \n",
    "\n",
    "\n",
    "Después cada parte pongo las variables de cada uno\n",
    "\n",
    "**df_prod_country**\n",
    "    'production_countries_United States of America'\n",
    "\n",
    "**df_prod_companies**\n",
    "     'production_companies_Paramount Pictures',\n",
    "\n",
    "**df_Keywords**\n",
    "    'Keywords_freq_rs',\n",
    " 'Keywords_independent film',\n",
    " 'Keywords_murder'\n",
    "\n",
    "\n",
    "\n",
    "He extraido informacion mediante el resumen breve de la sinopsis de la pelicula (overview).Para ello, he usado una metricas tfidf\n",
    "\n",
    "En la ultima seccion se ha creado el codigo ejecucion con sklearn pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e952df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_finales = ['budget_rs',\n",
    " 'popularity_rs',\n",
    " 'rd_year_rs',\n",
    " 'runtime_rs',\n",
    " 'crew_freq_rs',\n",
    " 'rd_mes_rs',\n",
    " 'cast_genero_1_rs',\n",
    " 'cast_genero_2_rs',\n",
    " 'man',\n",
    " 'rd_dia_semana_rs',\n",
    " 'Keywords_freq_rs',\n",
    " 'cast_genero_0_rs',\n",
    " 'secret',\n",
    " 'family',\n",
    " 'time',\n",
    " 'police',\n",
    " 'Keywords_independent film',\n",
    " 'woman',\n",
    " 'small',\n",
    " 'Keywords_murder',\n",
    " 'life',\n",
    " 'friend',\n",
    " 'production_companies_Paramount Pictures',\n",
    " 'war',\n",
    " 'years',\n",
    " 'friends',\n",
    " 'lives',\n",
    " 'love',\n",
    " 'mother',\n",
    " 'production_countries_United States of America',\n",
    " 'day',\n",
    " 'aos',\n",
    " 'team',\n",
    " 'boy',\n",
    " 'school',\n",
    " 'finds']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f57fa0f",
   "metadata": {},
   "source": [
    "# FUNCIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6638fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frecuencias_series(series, lista_posible, grafico=False):\n",
    "    \"\"\"series: serie con elementos en string separados por comas\n",
    "        lista_posible: todas las posibles strings en series\n",
    "        \"\"\"\n",
    "    aux = pd.Series( dtype='float64')\n",
    "    for elemento in list(lista_posible):\n",
    "    \n",
    "        n = series.apply(lambda x:  elemento in x).sum()/2100*100\n",
    "        aux = pd.concat([aux,pd.Series({elemento:n})] )\n",
    "    if grafico:\n",
    "        aux.sort_values().plot.barh()\n",
    "    return aux.sort_values()\n",
    "\n",
    "\n",
    "def lista_posibles(series):\n",
    "    aux = series.map(lambda x: sorted([d['name'] for d in get_dictionary(x)]))\n",
    "    generos = set()\n",
    "    for f in aux:\n",
    "        generos.update(f)\n",
    "    return generos\n",
    "\n",
    "\n",
    "\n",
    "def get_dictionary(s):\n",
    "    try:\n",
    "        d = eval(s)\n",
    "    except:\n",
    "        d = {}\n",
    "    return d\n",
    "\n",
    "def get_temp_var(df_cat):\n",
    "    a = df_cat.release_date.dt.year\n",
    "    b = df_cat.release_date.dt.month\n",
    "    c = df_cat.release_date.dt.dayofweek\n",
    "    d = df_cat.release_date.dt.quarter\n",
    "    x = pd.concat([a,b,c,d],axis=1)\n",
    "    x.columns = ['rd_year', 'rd_mes', 'rd_dia_semana', 'rd_cuatrimestre']\n",
    "    return x\n",
    "\n",
    "\n",
    "def conteo_genero(serie):\n",
    "    aux = []\n",
    "    for numero in [0,1,2]:\n",
    "        x = serie.apply(lambda lista: lista.count(numero))\n",
    "        aux.append(x)\n",
    "    df_aux = pd.concat(aux,axis=1)\n",
    "    df_aux.columns = ['cast_genero_0','cast_genero_1','cast_genero_2']\n",
    "    return df_aux\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e0c70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesamiento(cat):\n",
    "    cat = cat.copy()\n",
    "    #ELIMINAR\n",
    "    a_eliminar = ['belongs_to_collection','homepage','imdb_id','poster_path','tagline','spoken_languages',]\n",
    "    cat.drop(columns=a_eliminar,inplace=True)\n",
    "\n",
    "    #IMPUTACION\n",
    "    cat.genres.fillna('OTRO', inplace=True)\n",
    "    cat.production_companies.fillna('OTRO',inplace=True)\n",
    "    cat.production_countries.fillna('OTRO',inplace=True)\n",
    "    cat.Keywords.fillna('OTRO',inplace=True)\n",
    "    cat.cast.fillna('OTRO',inplace=True)\n",
    "    cat.crew.fillna('OTRO',inplace=True)\n",
    "\n",
    "    cat.release_date = pd.to_datetime(cat.release_date)\n",
    "\n",
    "\n",
    "\n",
    "    # LISTA VARIABLES\n",
    "    lista_vars =['genres','production_companies','production_countries','Keywords','cast','crew']\n",
    "    no_transformadas = [v for v in cat.columns.tolist() if v not in lista_vars]\n",
    "    no_transformadas\n",
    "\n",
    "    #DF VARIABLES SIN JSONS\n",
    "    aux = []\n",
    "    for var in lista_vars:\n",
    "        z = cat[var].map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\n",
    "        aux.append(z)\n",
    "\n",
    "\n",
    "    df_limpios = pd.concat(aux,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    #DF FRECUENCIAS DE VARIABLES LIMPIAS\n",
    "    aux = []\n",
    "    for column in df_limpios.columns:\n",
    "        z = df_limpios[column].map(lambda x: len(x.split(',')))\n",
    "        aux.append(z)\n",
    "    df_freq = pd.concat(aux,axis=1)\n",
    "    df_freq.columns = [var+\"_freq\" for var in df_freq.columns]\n",
    "    df_freq\n",
    "\n",
    "    # VARIABLES TIEMPO\n",
    "    df_temp = get_temp_var(cat)\n",
    "    df_temp['rd_year'] = np.where(df_temp['rd_year']>2020,df_temp['rd_year']-100,df_temp['rd_year'])\n",
    "\n",
    "    # frecuencia genero\n",
    "    z = cat['cast'].map(lambda x: sorted([d['gender'] for d in get_dictionary(x)]))\n",
    "    df_cast_genero_freq = conteo_genero(z)    \n",
    "    \n",
    "    \n",
    "    # UNIR TODOS LOS DATASETS\n",
    "    df_cat = pd.concat([cat[no_transformadas],df_temp,df_limpios,df_freq,df_cast_genero_freq],axis=1)\n",
    "\n",
    "\n",
    "    # VARIABLES NUEVA WINSORIZADO\n",
    "    df_cat['bin_english'] = np.where(df_cat.original_language=='en',1,0) \n",
    "    df_cat['genres_freq'] = np.where(df_cat['genres_freq']>4,4,df_cat['genres_freq'])\n",
    "    df_cat['production_companies_freq'] = np.where(df_cat['production_companies_freq']>4,4,df_cat['production_companies_freq'])\n",
    "    df_cat['production_countries_freq'] = np.where(df_cat['production_countries_freq']>1,1,0)\n",
    "\n",
    "\n",
    "    variable = 'Keywords_freq'\n",
    "    minimo = 0\n",
    "    maximo = 35\n",
    "    df_cat[variable].clip(minimo,maximo, inplace=True)\n",
    "\n",
    "    variable = 'cast_freq'\n",
    "    minimo = 0\n",
    "    maximo = 85\n",
    "    df_cat[variable].clip(minimo,maximo, inplace=True)\n",
    "\n",
    "    variable = 'crew_freq'\n",
    "    minimo = 0\n",
    "    maximo = 135\n",
    "    df_cat[variable].clip(minimo,maximo, inplace=True)\n",
    "    return df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "866b2c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineer 2\n",
    "# Funciones Ohe hot encoding\n",
    "\n",
    "def top_ohe(series, numero_top = 10):\n",
    "    \"\"\"devuelve variable binarias como estan\n",
    "    series: serie\n",
    "    \"\"\"\n",
    "    \n",
    "    aux = []\n",
    "    \n",
    "    # Top items\n",
    "    top_items = show_top_items(series,numero_top=10)\n",
    "    \n",
    "    for g in top_items:\n",
    "        x = series.apply(lambda x: 1  if  g == x else 0 )\n",
    "        x.name = series.name +\"_\"+g\n",
    "        aux.append(x)\n",
    "    \n",
    "    return pd.concat(aux,axis=1)\n",
    "\n",
    "\n",
    "def top_ohe_uniques(series, numero_top = 10):\n",
    "    \"\"\"devuelve variable binarias de valores unicos\n",
    "    series: serie\n",
    "    \"\"\"\n",
    "    \n",
    "    aux = []\n",
    "    \n",
    "    # Top items\n",
    "    top_items = show_top_items_unique(series,numero_top=10)\n",
    "    \n",
    "    for g in top_items:\n",
    "        x = series.apply(lambda x: 1  if  g in x else 0 )\n",
    "        x.name = series.name +\"_\"+g\n",
    "        aux.append(x)\n",
    "    \n",
    "    return pd.concat(aux,axis=1)\n",
    "\n",
    "########################################################\n",
    "# estas funciones se usan como INPUTS en las funciones de arriba\n",
    "\n",
    "def show_top_items(series,numero_top=10, freq=False):\n",
    "    \"\"\" devuelven los datos como estan (concatenados)\"\"\"\n",
    "    \n",
    "    mas_comunes = Counter(series).most_common(numero_top+10)\n",
    "    top_items = [m[0] for m in mas_comunes]\n",
    "    \n",
    "    if freq:\n",
    "        return mas_comunes\n",
    "    \n",
    "    if \"\" in top_items:\n",
    "        top_items.remove(\"\")\n",
    "    top_items = top_items[:numero_top]\n",
    "    top_items = [i.replace(',','_') for i in top_items ]\n",
    "    return top_items\n",
    "\n",
    "def show_top_items_unique(series,numero_top=10, freq=False):\n",
    "    \"\"\" devuelven los elementos unicos mas frecuentes\"\"\"\n",
    "    \n",
    "    #mas comunes\n",
    "    mas_comunes = Counter([i for j in series for i in j.split(',')]).most_common(10+numero_top)\n",
    "    \n",
    "    #cogemos los el indice\n",
    "    top_items = [m[0] for m in mas_comunes]\n",
    "    \n",
    "    if freq:\n",
    "        return mas_comunes\n",
    "    \n",
    "    if \"\" in top_items:\n",
    "        top_items.remove(\"\")\n",
    "    top_items = top_items[:numero_top]\n",
    "    top_items = [i.replace(',','_') for i in top_items ]\n",
    "    return top_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f5bbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ohe_var_series(series,elemento):\n",
    "    \"\"\"series : series\n",
    "        elemento :str\n",
    "    \"\"\"\n",
    "    \n",
    "    series_ohe = series.apply(lambda x: 1  if  elemento in x else 0 )\n",
    "    series_ohe.name = series.name +\"_\"+elemento\n",
    "    return series_ohe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63cfaf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_procesamiento_m1(_df_cat):\n",
    "    \n",
    "    diccionario_variables = {\n",
    "        'production_countries':['United States of America'],\n",
    "        'production_companies'  :['Paramount Pictures'],\n",
    "        'Keywords':['freq_rs', 'independent film', 'murder']\n",
    "        \n",
    "    }\n",
    "\n",
    "    aux = []\n",
    "    for variable, terminos in diccionario_variables.items():\n",
    "\n",
    "        for termino in terminos:\n",
    "            z= get_ohe_var_series( _df_cat[variable],termino)\n",
    "            aux.append(z)\n",
    "            \n",
    "    df_fei2 = pd.concat(aux,axis=1)\n",
    "    df_cat2 = pd.concat([_df_cat,df_fei2],axis=1)\n",
    "\n",
    "\n",
    "    return df_cat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f299b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_procesamiento(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    mean = df.runtime.mean()\n",
    "    df.runtime.fillna(mean,inplace=True)\n",
    "    \n",
    "    variable = 'runtime'\n",
    "    minimo = 70\n",
    "    maximo = 200\n",
    "\n",
    "    df[variable].clip(minimo,maximo, inplace=True)\n",
    "\n",
    "    variable = 'budget'\n",
    "    minimo = 0\n",
    "    maximo = 200000000\n",
    "\n",
    "    df[variable].clip(minimo,maximo, inplace=True)\n",
    "\n",
    "    variable = 'popularity'\n",
    "    minimo = 0\n",
    "    maximo = 50\n",
    "\n",
    "    df[variable].clip(minimo,maximo, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec39257e",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f615a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATOS ENTRENAMIENTO\n",
    "ruta_proyecto =  'C:/proyectos/03_PREDICCION_TAQUILLA'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b976e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datos train\n",
    "nombre_fichero_datos = 'train.csv'\n",
    "ruta_completa = ruta_proyecto + '/02_Datos/01_Originales/' + nombre_fichero_datos\n",
    "\n",
    "datos_train = pd.read_csv(ruta_completa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4af931fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = pre_procesamiento(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53b7ddb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     3000 non-null   int64  \n",
      " 1   belongs_to_collection  604 non-null    object \n",
      " 2   budget                 3000 non-null   int64  \n",
      " 3   genres                 2993 non-null   object \n",
      " 4   homepage               946 non-null    object \n",
      " 5   imdb_id                3000 non-null   object \n",
      " 6   original_language      3000 non-null   object \n",
      " 7   original_title         3000 non-null   object \n",
      " 8   overview               2992 non-null   object \n",
      " 9   popularity             3000 non-null   float64\n",
      " 10  poster_path            2999 non-null   object \n",
      " 11  production_companies   2844 non-null   object \n",
      " 12  production_countries   2945 non-null   object \n",
      " 13  release_date           3000 non-null   object \n",
      " 14  runtime                3000 non-null   float64\n",
      " 15  spoken_languages       2980 non-null   object \n",
      " 16  status                 3000 non-null   object \n",
      " 17  tagline                2403 non-null   object \n",
      " 18  title                  3000 non-null   object \n",
      " 19  Keywords               2724 non-null   object \n",
      " 20  cast                   2987 non-null   object \n",
      " 21  crew                   2984 non-null   object \n",
      " 22  revenue                3000 non-null   int64  \n",
      "dtypes: float64(2), int64(3), object(18)\n",
      "memory usage: 539.2+ KB\n"
     ]
    }
   ],
   "source": [
    "cat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eea4f143",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat =  procesamiento(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9dab860b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 36 columns):\n",
      " #   Column                                         Non-Null Count  Dtype         \n",
      "---  ------                                         --------------  -----         \n",
      " 0   id                                             3000 non-null   int64         \n",
      " 1   budget                                         3000 non-null   int64         \n",
      " 2   original_language                              3000 non-null   object        \n",
      " 3   original_title                                 3000 non-null   object        \n",
      " 4   overview                                       2992 non-null   object        \n",
      " 5   popularity                                     3000 non-null   float64       \n",
      " 6   release_date                                   3000 non-null   datetime64[ns]\n",
      " 7   runtime                                        3000 non-null   float64       \n",
      " 8   status                                         3000 non-null   object        \n",
      " 9   title                                          3000 non-null   object        \n",
      " 10  revenue                                        3000 non-null   int64         \n",
      " 11  rd_year                                        3000 non-null   int64         \n",
      " 12  rd_mes                                         3000 non-null   int64         \n",
      " 13  rd_dia_semana                                  3000 non-null   int64         \n",
      " 14  rd_cuatrimestre                                3000 non-null   int64         \n",
      " 15  genres                                         3000 non-null   object        \n",
      " 16  production_companies                           3000 non-null   object        \n",
      " 17  production_countries                           3000 non-null   object        \n",
      " 18  Keywords                                       3000 non-null   object        \n",
      " 19  cast                                           3000 non-null   object        \n",
      " 20  crew                                           3000 non-null   object        \n",
      " 21  genres_freq                                    3000 non-null   int64         \n",
      " 22  production_companies_freq                      3000 non-null   int64         \n",
      " 23  production_countries_freq                      3000 non-null   int32         \n",
      " 24  Keywords_freq                                  3000 non-null   int64         \n",
      " 25  cast_freq                                      3000 non-null   int64         \n",
      " 26  crew_freq                                      3000 non-null   int64         \n",
      " 27  cast_genero_0                                  3000 non-null   int64         \n",
      " 28  cast_genero_1                                  3000 non-null   int64         \n",
      " 29  cast_genero_2                                  3000 non-null   int64         \n",
      " 30  bin_english                                    3000 non-null   int32         \n",
      " 31  production_countries_United States of America  3000 non-null   int64         \n",
      " 32  production_companies_Paramount Pictures        3000 non-null   int64         \n",
      " 33  Keywords_freq_rs                               3000 non-null   int64         \n",
      " 34  Keywords_independent film                      3000 non-null   int64         \n",
      " 35  Keywords_murder                                3000 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int32(2), int64(20), object(11)\n",
      "memory usage: 820.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_cat2 = post_procesamiento_m1(df_cat)\n",
    "df_cat2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1178f6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2b = XGBRegressor(base_score=0.5, booster='gbtree',\n",
    "                              colsample_bylevel=1, colsample_bynode=1,\n",
    "                              colsample_bytree=1, enable_categorical=False,\n",
    "                              gamma=0.5, gpu_id=-1, importance_type=None,\n",
    "                              interaction_constraints='', learning_rate=0.01,\n",
    "                              max_delta_step=0, max_depth=3, min_child_weight=1,\n",
    "                               monotone_constraints='()',\n",
    "                              n_estimators=500, n_jobs=8, num_parallel_tree=1,\n",
    "                              predictor='auto', random_state=0, reg_alpha=0,\n",
    "                              reg_lambda=0.01, scale_pos_weight=1, subsample=1,\n",
    "                              tree_method='exact', validate_parameters=1,\n",
    "                              verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb889eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acrespod\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'daren', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'itse', 'll', 'mayn', 'mightn', 'mon', 'mustn', 'myse', 'needn', 'oughtn', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "stop = pd.read_csv(ruta_proyecto + '/01_Documentos/stop_words_english.txt',names = ['termino'])\n",
    "\n",
    "def quitar_tildes(palabra):\n",
    "    #Definimos la versión con tildes y símbolos y la sin\n",
    "    con = 'áéíóúüñÁÉÍÓÚÜÑ'\n",
    "    sin = 'aeiouunAEIOUUN'\n",
    "    #Creamos un traductor\n",
    "    traductor = str.maketrans(con,sin)\n",
    "    #Aplicamos el traductor y devolvemos la palabra limpia\n",
    "    return(palabra.translate(traductor))\n",
    "\n",
    "stop['limpias'] = stop.termino.transform(quitar_tildes)\n",
    "def get_variables_tfidf(stop, df_cat2):\n",
    "    # #Instanciamos\n",
    "    tfidf = TfidfVectorizer(strip_accents = 'unicode',\n",
    "                     stop_words = stop.limpias.to_list(),\n",
    "                     max_df = 0.7,\n",
    "                     min_df = 50,\n",
    "                     ngram_range = (1,3),\n",
    "                     max_features = 50)\n",
    "\n",
    "    # #Entrenamos y aplicamos\n",
    "    df_tfidf_i = tfidf.fit_transform(df_cat2.overview.fillna(''))\n",
    "    df_tfidf = pd.DataFrame.sparse.from_spmatrix(df_tfidf_i,columns = tfidf.get_feature_names(),index=df_cat2.id)\n",
    "\n",
    "    palabras_elegidas = ['man',\n",
    " 'secret',\n",
    " 'family',\n",
    " 'time',\n",
    " 'police',\n",
    " 'woman',\n",
    " 'small',\n",
    " 'life',\n",
    " 'friend',\n",
    " 'war',\n",
    " 'years',\n",
    " 'friends',\n",
    " 'lives',\n",
    " 'love',\n",
    " 'mother',\n",
    " 'day',\n",
    " 'aos',\n",
    " 'team',\n",
    " 'boy',\n",
    " 'school',\n",
    " 'finds']\n",
    "    palabras_que_no_estan =[column for column in palabras_elegidas if column not in df_tfidf.columns]\n",
    "    for palabra in palabras_que_no_estan:\n",
    "        df_tfidf[palabra]=0\n",
    "        \n",
    "    return df_tfidf.loc[:,palabras_elegidas]\n",
    "\n",
    "\n",
    "df_tfidf =  get_variables_tfidf(stop, df_cat2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "16a22b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_proyecto =['budget',\n",
    " 'popularity',\n",
    " 'rd_year',\n",
    " 'runtime',\n",
    " 'crew_freq',\n",
    " 'rd_mes',\n",
    " 'cast_genero_1',\n",
    " 'cast_genero_2',\n",
    " 'rd_dia_semana',\n",
    " 'cast_genero_0',\n",
    " 'Keywords_freq',\n",
    " 'Keywords_independent film',\n",
    " 'Keywords_murder',\n",
    " 'production_companies_Paramount Pictures',\n",
    " 'production_countries_United States of America']\n",
    "\n",
    "df_cat3 = pd.concat([df_cat2[variables_proyecto],df_tfidf[palabras_elegidas].reset_index() ],axis=1).set_index('id').copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "32d25ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN / TEST\n",
    "y = df_cat2['revenue'].transform(np.log1p)\n",
    "x= df_cat3.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "26403f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROBUST SCALER\n",
    "var_rs = ['budget','popularity','rd_year','runtime',\n",
    "         'crew_freq','rd_mes','cast_genero_1','cast_genero_2',\n",
    "         'rd_dia_semana','cast_genero_0']\n",
    "rs = RobustScaler(quantile_range=(10.0, 90.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d4e6ff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINE\n",
    "ct = make_column_transformer(\n",
    "    (rs, var_rs),\n",
    "    remainder='passthrough')\n",
    "\n",
    "# ct.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c01cffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_entrenamiento = make_pipeline(ct,m2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eb75d1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('robustscaler',\n",
       "                                                  RobustScaler(quantile_range=(10.0,\n",
       "                                                                               90.0)),\n",
       "                                                  ['budget', 'popularity',\n",
       "                                                   'rd_year', 'runtime',\n",
       "                                                   'crew_freq', 'rd_mes',\n",
       "                                                   'cast_genero_1',\n",
       "                                                   'cast_genero_2',\n",
       "                                                   'rd_dia_semana',\n",
       "                                                   'cast_genero_0'])])),\n",
       "                ('xgbregressor',\n",
       "                 XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                              colsam...\n",
       "                              gamma=0.5, gpu_id=-1, importance_type=None,\n",
       "                              interaction_constraints='', learning_rate=0.01,\n",
       "                              max_delta_step=0, max_depth=3, min_child_weight=1,\n",
       "                              missing=nan, monotone_constraints='()',\n",
       "                              n_estimators=500, n_jobs=8, num_parallel_tree=1,\n",
       "                              predictor='auto', random_state=0, reg_alpha=0,\n",
       "                              reg_lambda=0.01, scale_pos_weight=1, subsample=1,\n",
       "                              tree_method='exact', validate_parameters=1,\n",
       "                              verbosity=None))])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_entrenamiento.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb49fc9e",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "113febf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_fichero_datos = \"test.csv\"\n",
    "ruta_completa = ruta_proyecto + '/02_Datos/01_Originales/' + nombre_fichero_datos\n",
    "\n",
    "datos = pd.read_csv(ruta_completa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23aa9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "72522985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acrespod\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'daren', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'itse', 'll', 'mayn', 'mightn', 'mon', 'mustn', 'myse', 'needn', 'oughtn', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "cat = pre_procesamiento(datos)\n",
    "df_cat =  procesamiento(cat)\n",
    "df_cat2 = post_procesamiento_m1(df_cat)\n",
    "df_tfidf  =  get_variables_tfidf(stop, df_cat2)\n",
    "\n",
    "\n",
    "variables_proyecto =['budget',\n",
    " 'popularity',\n",
    " 'rd_year',\n",
    " 'runtime',\n",
    " 'crew_freq',\n",
    " 'rd_mes',\n",
    " 'cast_genero_1',\n",
    " 'cast_genero_2',\n",
    " 'rd_dia_semana',\n",
    " 'cast_genero_0',\n",
    " 'Keywords_freq',\n",
    " 'Keywords_independent film',\n",
    " 'Keywords_murder',\n",
    " 'production_companies_Paramount Pictures',\n",
    " 'production_countries_United States of America']\n",
    "\n",
    "df_cat3 = pd.concat([df_cat2[variables_proyecto],df_tfidf[palabras_elegidas].reset_index() ],axis=1).set_index('id').copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4c2de7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(variables_proyecto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "06cf99d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>popularity</th>\n",
       "      <th>rd_year</th>\n",
       "      <th>runtime</th>\n",
       "      <th>crew_freq</th>\n",
       "      <th>rd_mes</th>\n",
       "      <th>cast_genero_1</th>\n",
       "      <th>cast_genero_2</th>\n",
       "      <th>rd_dia_semana</th>\n",
       "      <th>cast_genero_0</th>\n",
       "      <th>...</th>\n",
       "      <th>friends</th>\n",
       "      <th>lives</th>\n",
       "      <th>love</th>\n",
       "      <th>mother</th>\n",
       "      <th>day</th>\n",
       "      <th>aos</th>\n",
       "      <th>team</th>\n",
       "      <th>boy</th>\n",
       "      <th>school</th>\n",
       "      <th>finds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>0</td>\n",
       "      <td>3.851534</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>88000</td>\n",
       "      <td>3.559789</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>0</td>\n",
       "      <td>8.085194</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.398307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>6800000</td>\n",
       "      <td>8.596012</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>69</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.553859</td>\n",
       "      <td>0.658021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>2000000</td>\n",
       "      <td>3.217680</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7394</th>\n",
       "      <td>42000000</td>\n",
       "      <td>9.970359</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7395</th>\n",
       "      <td>19000000</td>\n",
       "      <td>6.046516</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>94</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387658</td>\n",
       "      <td>0.396817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396</th>\n",
       "      <td>16000000</td>\n",
       "      <td>9.596883</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7397</th>\n",
       "      <td>2000000</td>\n",
       "      <td>20.359336</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.594083</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7398</th>\n",
       "      <td>64000</td>\n",
       "      <td>11.305910</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>25</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4398 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        budget  popularity  rd_year  runtime  crew_freq  rd_mes  \\\n",
       "id                                                                \n",
       "3001         0    3.851534   2007.0     90.0          2     7.0   \n",
       "3002     88000    3.559789   1958.0     70.0          8     5.0   \n",
       "3003         0    8.085194   1997.0    100.0         10     5.0   \n",
       "3004   6800000    8.596012   2010.0    130.0         69     9.0   \n",
       "3005   2000000    3.217680   2005.0     92.0         14     2.0   \n",
       "...        ...         ...      ...      ...        ...     ...   \n",
       "7394  42000000    9.970359   2001.0    118.0         11     8.0   \n",
       "7395  19000000    6.046516   2004.0     95.0         94     8.0   \n",
       "7396  16000000    9.596883   1982.0    129.0         12    12.0   \n",
       "7397   2000000   20.359336   2015.0    100.0         29     2.0   \n",
       "7398     64000   11.305910   1962.0     85.0         25     9.0   \n",
       "\n",
       "      cast_genero_1  cast_genero_2  rd_dia_semana  cast_genero_0  ...  \\\n",
       "id                                                                ...   \n",
       "3001              3              0            5.0              4  ...   \n",
       "3002              2              2            6.0              6  ...   \n",
       "3003              4              5            4.0              0  ...   \n",
       "3004              3              5            5.0             15  ...   \n",
       "3005              0              4            4.0              0  ...   \n",
       "...             ...            ...            ...            ...  ...   \n",
       "7394              4              6            4.0              0  ...   \n",
       "7395              5              9            4.0              8  ...   \n",
       "7396              4             13            2.0              0  ...   \n",
       "7397             11              6            2.0             12  ...   \n",
       "7398              1              2            2.0             16  ...   \n",
       "\n",
       "       friends     lives      love    mother  day  aos  team  boy    school  \\\n",
       "id                                                                            \n",
       "3001  0.367590  0.000000  0.000000  0.000000  0.0  0.0   0.0  0.0  0.000000   \n",
       "3002  0.000000  0.000000  0.000000  0.000000  0.0  0.0   0.0  0.0  0.000000   \n",
       "3003  0.000000  0.000000  0.398307  0.000000  0.0  0.0   0.0  0.0  0.000000   \n",
       "3004  0.000000  0.000000  0.553859  0.658021  0.0  0.0   0.0  0.0  0.000000   \n",
       "3005  0.000000  0.000000  0.000000  0.000000  0.0  0.0   0.0  0.0  0.000000   \n",
       "...        ...       ...       ...       ...  ...  ...   ...  ...       ...   \n",
       "7394  0.000000  0.000000  0.000000  0.000000  0.0  0.0   0.0  0.0  0.000000   \n",
       "7395  0.387658  0.396817  0.000000  0.000000  0.0  0.0   0.0  0.0  0.000000   \n",
       "7396  0.000000  0.000000  0.000000  0.000000  0.0  0.0   0.0  0.0  0.000000   \n",
       "7397  0.565380  0.000000  0.000000  0.000000  0.0  0.0   0.0  0.0  0.594083   \n",
       "7398  0.000000  0.000000  0.000000  0.000000  0.0  0.0   0.0  0.0  0.000000   \n",
       "\n",
       "      finds  \n",
       "id           \n",
       "3001    0.0  \n",
       "3002    0.0  \n",
       "3003    0.0  \n",
       "3004    0.0  \n",
       "3005    0.0  \n",
       "...     ...  \n",
       "7394    0.0  \n",
       "7395    0.0  \n",
       "7396    0.0  \n",
       "7397    0.0  \n",
       "7398    0.0  \n",
       "\n",
       "[4398 rows x 36 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_cat3.info()\n",
    "df_cat3.reset_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ea1d4896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(_df):\n",
    "    # la prediccion el modelo la hace log revenue. hay que cambiar\n",
    "    prediction = np.exp(pipe_entrenamiento.predict(_df))\n",
    "    df_submit = pd.DataFrame({'revenue':prediction}, index=_df.reset_index().id)\n",
    "    nombre_cat = \"submit.csv\"\n",
    "    df_submit.to_csv(ruta_proyecto + '/03_Notebooks/03_Sistema/' + nombre_cat)\n",
    "    \n",
    "submit(df_cat3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05489b48",
   "metadata": {},
   "source": [
    "# Usando pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2f793c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = pd.read_csv(ruta_proyecto + '/01_Documentos/stop_words_english.txt',names = ['termino'])\n",
    "\n",
    "def quitar_tildes(palabra):\n",
    "    #Definimos la versión con tildes y símbolos y la sin\n",
    "    con = 'áéíóúüñÁÉÍÓÚÜÑ'\n",
    "    sin = 'aeiouunAEIOUUN'\n",
    "    #Creamos un traductor\n",
    "    traductor = str.maketrans(con,sin)\n",
    "    #Aplicamos el traductor y devolvemos la palabra limpia\n",
    "    return(palabra.translate(traductor))\n",
    "\n",
    "stop['limpias'] = stop.termino.transform(quitar_tildes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34e8b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "cat = pre_procesamiento(datos_train)\n",
    "df_cat =  procesamiento(cat)\n",
    "df_cat2 = post_procesamiento_m1(df_cat)\n",
    "df_cat2.overview = df_cat2.overview.fillna('')\n",
    "\n",
    "y = np.log1p(df_cat2['revenue'])\n",
    "x = df_cat2.drop(columns=['revenue'])\n",
    "\n",
    "\n",
    "\n",
    "var_reescalado_robusto = ['budget','popularity','rd_year','runtime',\n",
    "         'crew_freq','rd_mes','cast_genero_1','cast_genero_2',\n",
    "         'rd_dia_semana','cast_genero_0']\n",
    "reescalado_robusto = RobustScaler(quantile_range=(10.0, 90.0))\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents = 'unicode',\n",
    "                     stop_words = stop.limpias.to_list(),\n",
    "                     max_df = 0.7,\n",
    "                     ngram_range = (1,3),\n",
    "                     max_features = 50)\n",
    "\n",
    "m2b = XGBRegressor(base_score=0.5, booster='gbtree',\n",
    "                              colsample_bylevel=1, colsample_bynode=1,\n",
    "                              colsample_bytree=1, enable_categorical=False,\n",
    "                              gamma=0.5, gpu_id=-1, importance_type=None,\n",
    "                              interaction_constraints='', learning_rate=0.01,\n",
    "                              max_delta_step=0, max_depth=3, min_child_weight=1,\n",
    "                               monotone_constraints='()',\n",
    "                              n_estimators=500, n_jobs=8, num_parallel_tree=1,\n",
    "                              predictor='auto', random_state=0, reg_alpha=0,\n",
    "                              reg_lambda=0.01, scale_pos_weight=1, subsample=1,\n",
    "                              tree_method='exact', validate_parameters=1,\n",
    "                              verbosity=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89158a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIONES\n",
    "\n",
    "def seleccionar_variables_tdidf(df_tfidf_i):\n",
    "    df_tfidf = pd.DataFrame.sparse.from_spmatrix(df_tfidf_i,columns = tfidf.get_feature_names())\n",
    "\n",
    "    palabras_elegidas = ['man',\n",
    " 'secret',\n",
    " 'family',\n",
    " 'time',\n",
    " 'police',\n",
    " 'woman',\n",
    " 'small',\n",
    " 'life',\n",
    " 'friend',\n",
    " 'war',\n",
    " 'years',\n",
    " 'friends',\n",
    " 'lives',\n",
    " 'love',\n",
    " 'mother',\n",
    " 'day',\n",
    " 'aos',\n",
    " 'team',\n",
    " 'boy',\n",
    " 'school',\n",
    " 'finds']\n",
    "    palabras_que_no_estan =[column for column in palabras_elegidas if column not in df_tfidf.columns]\n",
    "    for palabra in palabras_que_no_estan:\n",
    "        df_tfidf[palabra]=0\n",
    "    return df_tfidf[palabras_elegidas].sparse.to_dense()\n",
    "\n",
    "def selector_variables(df):\n",
    "    return df\n",
    "\n",
    "# FUNCIONES A TRANSFORMERS\n",
    "# seleccionar_variables_tdidf_pipe=FunctionTransformer(seleccionar_variables_tdidf,kw_args={'tfidf':[tfidf]})\n",
    "seleccionar_variables_tdidf_pipe=FunctionTransformer(seleccionar_variables_tdidf)\n",
    "selector_variables_pipe=FunctionTransformer(selector_variables)\n",
    "\n",
    "#PIPELINE TEXTO\n",
    "text_features_pipe = make_pipeline(tfidf,seleccionar_variables_tdidf_pipe)\n",
    "\n",
    "text_features_pipe.fit_transform(x['overview'])\n",
    "text_features_pipe.named_steps.tfidfvectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "variables_ohe=[ 'Keywords_freq',\n",
    "     'Keywords_independent film',\n",
    "     'Keywords_murder',\n",
    "     'production_companies_Paramount Pictures',\n",
    "     'production_countries_United States of America']\n",
    "\n",
    "# COLUMN TRANSFORM\n",
    "column_transformer_total = make_column_transformer(\n",
    "    (reescalado_robusto, var_reescalado_robusto),\n",
    "    (text_features_pipe,'overview'),\n",
    "    (selector_variables_pipe,variables_ohe),\n",
    "    remainder='drop')\n",
    "\n",
    "\n",
    "# variables tfidf\n",
    "palabras_elegidas = ['man',\n",
    " 'secret',\n",
    " 'family',\n",
    " 'time',\n",
    " 'police',\n",
    " 'woman',\n",
    " 'small',\n",
    " 'life',\n",
    " 'friend',\n",
    " 'war',\n",
    " 'years',\n",
    " 'friends',\n",
    " 'lives',\n",
    " 'love',\n",
    " 'mother',\n",
    " 'day',\n",
    " 'aos',\n",
    " 'team',\n",
    " 'boy',\n",
    " 'school',\n",
    " 'finds']\n",
    "\n",
    "\n",
    "variables = var_reescalado_robusto + palabras_elegidas +variables_ohe\n",
    "\n",
    "# PIPELINE\n",
    "pipe_entrenamiento = make_pipeline(column_transformer_total,m2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ac73b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acrespod\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'daren', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'itse', 'll', 'mayn', 'mightn', 'mon', 'mustn', 'myse', 'needn', 'oughtn', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('robustscaler',\n",
       "                                                  RobustScaler(quantile_range=(10.0,\n",
       "                                                                               90.0)),\n",
       "                                                  ['budget', 'popularity',\n",
       "                                                   'rd_year', 'runtime',\n",
       "                                                   'crew_freq', 'rd_mes',\n",
       "                                                   'cast_genero_1',\n",
       "                                                   'cast_genero_2',\n",
       "                                                   'rd_dia_semana',\n",
       "                                                   'cast_genero_0']),\n",
       "                                                 ('pipeline',\n",
       "                                                  Pipeline(steps=[('tfidfvectorizer',\n",
       "                                                                   TfidfVectorizer(max_df=0.7,\n",
       "                                                                                   max_features=50,\n",
       "                                                                                   ngra...\n",
       "                              gamma=0.5, gpu_id=-1, importance_type=None,\n",
       "                              interaction_constraints='', learning_rate=0.01,\n",
       "                              max_delta_step=0, max_depth=3, min_child_weight=1,\n",
       "                              missing=nan, monotone_constraints='()',\n",
       "                              n_estimators=500, n_jobs=8, num_parallel_tree=1,\n",
       "                              predictor='auto', random_state=0, reg_alpha=0,\n",
       "                              reg_lambda=0.01, scale_pos_weight=1, subsample=1,\n",
       "                              tree_method='exact', validate_parameters=1,\n",
       "                              verbosity=None))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_entrenamiento.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ae16070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.695292, 18.017952, 16.653389, ..., 18.584694, 18.316553,\n",
       "       17.929972], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ENTRENAMIENTO\n",
    "pipe_entrenamiento.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1aa7832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 35 columns):\n",
      " #   Column                                         Non-Null Count  Dtype         \n",
      "---  ------                                         --------------  -----         \n",
      " 0   id                                             3000 non-null   int64         \n",
      " 1   budget                                         3000 non-null   int64         \n",
      " 2   original_language                              3000 non-null   object        \n",
      " 3   original_title                                 3000 non-null   object        \n",
      " 4   overview                                       3000 non-null   object        \n",
      " 5   popularity                                     3000 non-null   float64       \n",
      " 6   release_date                                   3000 non-null   datetime64[ns]\n",
      " 7   runtime                                        3000 non-null   float64       \n",
      " 8   status                                         3000 non-null   object        \n",
      " 9   title                                          3000 non-null   object        \n",
      " 10  rd_year                                        3000 non-null   int64         \n",
      " 11  rd_mes                                         3000 non-null   int64         \n",
      " 12  rd_dia_semana                                  3000 non-null   int64         \n",
      " 13  rd_cuatrimestre                                3000 non-null   int64         \n",
      " 14  genres                                         3000 non-null   object        \n",
      " 15  production_companies                           3000 non-null   object        \n",
      " 16  production_countries                           3000 non-null   object        \n",
      " 17  Keywords                                       3000 non-null   object        \n",
      " 18  cast                                           3000 non-null   object        \n",
      " 19  crew                                           3000 non-null   object        \n",
      " 20  genres_freq                                    3000 non-null   int64         \n",
      " 21  production_companies_freq                      3000 non-null   int64         \n",
      " 22  production_countries_freq                      3000 non-null   int32         \n",
      " 23  Keywords_freq                                  3000 non-null   int64         \n",
      " 24  cast_freq                                      3000 non-null   int64         \n",
      " 25  crew_freq                                      3000 non-null   int64         \n",
      " 26  cast_genero_0                                  3000 non-null   int64         \n",
      " 27  cast_genero_1                                  3000 non-null   int64         \n",
      " 28  cast_genero_2                                  3000 non-null   int64         \n",
      " 29  bin_english                                    3000 non-null   int32         \n",
      " 30  production_countries_United States of America  3000 non-null   int64         \n",
      " 31  production_companies_Paramount Pictures        3000 non-null   int64         \n",
      " 32  Keywords_freq_rs                               3000 non-null   int64         \n",
      " 33  Keywords_independent film                      3000 non-null   int64         \n",
      " 34  Keywords_murder                                3000 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int32(2), int64(19), object(11)\n",
      "memory usage: 797.0+ KB\n"
     ]
    }
   ],
   "source": [
    "x.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260aebbc",
   "metadata": {},
   "source": [
    "## TEST PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd5332e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nombre_fichero_datos = \"test.csv\"\n",
    "ruta_completa = ruta_proyecto + '/02_Datos/01_Originales/' + nombre_fichero_datos\n",
    "datos = pd.read_csv(ruta_completa)\n",
    "\n",
    "cat = pre_procesamiento(datos)\n",
    "df_cat =  procesamiento(cat)\n",
    "df_cat2 = post_procesamiento_m1(df_cat)\n",
    "df_cat2['overview'] = df_cat2['overview'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f95ea00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  448480.3,  1187293.1,  4515844.5, ..., 42522752. ,  3538798.2,\n",
       "        2510489.2], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones = np.expm1(pipe_entrenamiento.predict(df_cat2))\n",
    "predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b506fd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.062px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
